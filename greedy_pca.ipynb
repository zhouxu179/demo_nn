{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2]\n",
      "5 [1 3 5]\n",
      "[8, 40, 128] [16, 32, 64] 3 3\n",
      "10000 (10000L, 3L, 32L, 32L)\n",
      "20000 (10000L, 3L, 32L, 32L)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-14 17:42:08.660063. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#greedy pca net\n",
    "############################ set hyperparameters ###############################\n",
    "import find_mxnet\n",
    "assert find_mxnet\n",
    "import mxnet as mx\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ks = 3\n",
    "pks = 3\n",
    "hks = (ks-1)/2\n",
    "hpks = (pks-1)/2\n",
    "num_filters1=[8,40,128]\n",
    "#num_filters1=[16,16,16,16]\n",
    "num_filters2=[16,32,64]\n",
    "layer = 2\n",
    "num_layers = np.array([1,layer,layer])\n",
    "print num_layers\n",
    "num_levels = num_layers.size\n",
    "num_conv = num_layers.sum()\n",
    "end_layers = np.zeros(num_levels,dtype=int)\n",
    "for i in range(num_levels):\n",
    "    end_layers[i] = np.sum(num_layers[0:i+1])\n",
    "\n",
    "print num_conv, end_layers\n",
    "    \n",
    "lr_mult  = 1.0\n",
    "log_file = 'greedy_pca'\n",
    "log_dir = 'cifar10'\n",
    "\n",
    "batch_size = 100\n",
    "magnitude = 1e-2\n",
    "num_epoch = 50\n",
    "learning_rate = 1e-1\n",
    "momentum = 0.9\n",
    "eps = 1e-4\n",
    "load_epoch = None\n",
    "num_gpu = 2\n",
    "devs = [mx.gpu(int(i)) for i in range(num_gpu)]\n",
    "kv_store = 'local'\n",
    "num_examples = 50000\n",
    "num_train = 50000\n",
    "data_dir = 'cifar/'\n",
    "chk_dir = 'model/'\n",
    "chk_prefix = chk_dir + log_file\n",
    "r = None\n",
    "\n",
    "epoch_size = num_examples / batch_size\n",
    "factor = 0.95\n",
    "\n",
    "################################  path #########################################\n",
    "\n",
    "# download data if necessary\n",
    "def _download(data_dir):\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.system(\"mkdir \" + data_dir)\n",
    "    os.chdir(data_dir)\n",
    "    if (not os.path.exists('train.rec')) or \\\n",
    "       (not os.path.exists('test.rec')) :\n",
    "        os.system(\"wget http://data.dmlc.ml/mxnet/data/cifar10.zip\")\n",
    "        os.system(\"unzip -u cifar10.zip\")\n",
    "        os.system(\"mv cifar/* .; rm -rf cifar; rm cifar10.zip\")\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "\n",
    "\n",
    "def log_to_list(period,lst):\n",
    "    def _callback(param):\n",
    "        if (param.nbatch+1) % period == 0 and param.eval_metric is not None:\n",
    "            name_value = param.eval_metric.get_name_value()\n",
    "            for name, value in name_value:\n",
    "                lst.append(value)\n",
    "    return _callback\n",
    "\n",
    "# data\n",
    "def get_iterator(data_dir, batch_size):\n",
    "    kargs = dict(\n",
    "        data_shape=(3, 32, 32),\n",
    "    )\n",
    "    if '://' not in data_dir:\n",
    "        _download(data_dir)     \n",
    "        \n",
    "        \n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec=data_dir + 'train.rec',\n",
    "        batch_size=batch_size,\n",
    "        rand_crop=True,\n",
    "        rand_mirror=True,\n",
    "        pad=4,\n",
    "        fill_value=127,\n",
    "        shuffle=True,\n",
    "        **kargs\n",
    "    )\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec=data_dir + 'test.rec',\n",
    "        rand_crop=False,\n",
    "        rand_mirror=False,\n",
    "        batch_size=batch_size,\n",
    "        **kargs\n",
    "    )\n",
    "    return (train,val)\n",
    "\n",
    "def PCA(data, r = 0.95, k = None):\n",
    "    \"\"\"\n",
    "    returns: data transformed in 2 dims/columns + regenerated original data\n",
    "    pass in: data as 2D NumPy array\n",
    "    \"\"\"\n",
    "    from scipy import linalg as la\n",
    "    m, n = data.shape\n",
    "    # mean center the data\n",
    "    data -= data.mean(axis=0)\n",
    "    # calculate the covariance matrix\n",
    "    #R = np.cov(data, rowvar=False)\n",
    "    R = np.dot(data,data.T)/float(n)\n",
    "    evals, evecs = la.eigh(R)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    idx = np.argsort(evals)[::-1]\n",
    "    evecs = evecs[:,idx]\n",
    "    # sort eigenvectors according to same index\n",
    "    evals = evals[idx]\n",
    "\n",
    "    # carry out the transformation on the data using eigenvectors\n",
    "    # and return the re-scaled data, eigenvalues, and eigenvectors\n",
    "    sum_evals = np.sum(evals)\n",
    "    if r is not None and k is None:\n",
    "        for i in range(m):\n",
    "            ratio = np.sum(evals[0:i])/sum_evals\n",
    "            if ratio>=r:\n",
    "                k = i\n",
    "                break\n",
    "    elif k is not None:\n",
    "        ratio = np.sum(evals[0:k])/sum_evals\n",
    "    \n",
    "    # select the first k eigenvectors \n",
    "    evecs = evecs[:, :k]           \n",
    "    print 'The ratio of the first %d eigenvalues is %f'%(k,ratio)\n",
    "    return evals, evecs  \n",
    "\n",
    "def get_block(data,level,layer,num_filter1,num_filter2,ks,hks,pks,hpks,momentum=0.9):\n",
    "    data = mx.sym.Convolution(data=data,name=\"pca\"+str(level)+str(layer), kernel=(pks,pks), pad=(hpks,hpks), num_filter=num_filter1, no_bias=True)\n",
    "    data = mx.sym.Convolution(data=data,name=\"alpha\"+str(level)+str(layer), kernel=(1,1), pad=(0,0), num_filter=num_filter2)\n",
    "    data = mx.symbol.BatchNorm(data=data, name=\"bn\"+str(level)+str(layer), fix_gamma=False, momentum=momentum, eps=2e-5)\n",
    "    data = mx.symbol.Activation(data=data, act_type=\"relu\", name=\"relu\"+str(level)+str(layer))\n",
    "        \n",
    "    return data\n",
    "print num_filters1,num_filters2, ks, pks\n",
    "\n",
    "def get_net(num_classes=10,num_filters1=num_filters1,num_filters2=num_filters2,num_levels=num_levels,num_layers=num_layers,ks=ks, pks=pks, pool_kernel = (2,2), lr_mult=0.0):\n",
    "    hks = int((ks-1)/2)\n",
    "    hpks = int((pks-1)/2)\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "    for l in range(num_levels):\n",
    "        num_filter1 = num_filters1[l]\n",
    "        num_filter2 = num_filters2[l]\n",
    "        layers = num_layers[l]   \n",
    "        for layer in range(layers):\n",
    "            data = get_block(data=data,level=l+1,layer=layer+1,num_filter1=num_filter1,num_filter2=num_filter2,ks=ks,hks=hks,pks=pks,hpks=hpks)\n",
    "        if l<num_levels-1:\n",
    "            data = mx.sym.Pooling(data=data, name=\"pool\"+str(l+1), pool_type=\"max\", kernel=(2, 2),stride=(2, 2))\n",
    "    \n",
    "    pool = mx.symbol.Pooling(data=data, kernel=pool_kernel, pool_type='avg')\n",
    "    flat = mx.symbol.Flatten(data=pool)\n",
    "    fc = mx.symbol.FullyConnected(data=flat, num_hidden=num_classes, name='fc')\n",
    "    softmax = mx.sym.SoftmaxOutput(data=fc, name='softmax')\n",
    "    return softmax\n",
    "\n",
    "def get_im2col_indices(x_shape, field_height, field_width, padding=1, stride=1):\n",
    "  # First figure out what the size of the output should be\n",
    "  N, C, H, W = x_shape\n",
    "  assert (H + 2 * padding - field_height) % stride == 0\n",
    "  assert (W + 2 * padding - field_height) % stride == 0\n",
    "  out_height = (H + 2 * padding - field_height) / stride + 1\n",
    "  out_width = (W + 2 * padding - field_width) / stride + 1\n",
    "\n",
    "  i0 = np.repeat(np.arange(field_height), field_width)\n",
    "  i0 = np.tile(i0, C)\n",
    "  i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "  j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "  j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "  i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "  j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "  k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "  return (k, i, j)\n",
    "\n",
    "\n",
    "def im2col_indices(x, field_height, field_width, padding=1, stride=1):\n",
    "  \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
    "  # Zero-pad the input\n",
    "  p = padding\n",
    "  x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
    "\n",
    "  k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding, stride)\n",
    "\n",
    "  cols = x_padded[:, k, i, j]\n",
    "  C = x.shape[1]\n",
    "  cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
    "  return cols\n",
    "\n",
    "\n",
    "def get_patches(data,patch_size = (3,3)):\n",
    "    # data: numpy array of shape N,C,H,W\n",
    "    data_type = type(data)\n",
    "    if data_type ==  type(mx.nd.array([1])):\n",
    "        data = data.asnumpy()\n",
    "\n",
    "    N,C,H,W = data.shape\n",
    "    cols = im2col_indices(data, patch_size[0], patch_size[1], 0, 1)\n",
    "    return cols\n",
    "\n",
    "def layer_forward(ctx,f_in,args_all,aux_all,level,layer,num_filter1,num_filter2,ks,hks,pks,hpks,momentum=0.9,pooling=False):\n",
    "    f = mx.symbol.Variable(name=\"data\")\n",
    "    f = get_block(f,level+1,layer+1,num_filter1,num_filter2,ks,hks,pks,hpks,momentum)\n",
    "    if pooling:\n",
    "        f = mx.sym.Pooling(data=f, name=\"pool\"+str(level+1), pool_type=\"max\", kernel=(2, 2),stride=(2, 2))\n",
    "    executor =f.simple_bind(ctx=ctx, data=f_in.shape, grad_req='null')\n",
    "    args = executor.arg_dict\n",
    "    aux = executor.aux_dict\n",
    "    for key in args:\n",
    "        if key != 'data':\n",
    "            args[key][:] = args_all[key]\n",
    "    args['data'][:] = f_in\n",
    "\n",
    "    for key in aux:\n",
    "        aux[key][:] = aux_all[key]\n",
    "\n",
    "    executor.forward(is_train=False)\n",
    "    f_out = executor.outputs[0]\n",
    "    print 'f_out:', f_out\n",
    "    #print 'layer forward name:', name\n",
    "    return f_out\n",
    "\n",
    "def mod_layer_forward(ctx,f_in,args_all,aux_all,level,layer,num_filter1,num_filter2,ks,hks,pks,hpks,momentum=0.9,pooling=False):\n",
    "    f = mx.symbol.Variable(name=\"data\")\n",
    "    f = get_block(f,level+1,layer+1,num_filter1,num_filter2,ks,hks,pks,hpks,momentum)\n",
    "    if pooling:\n",
    "        f = mx.sym.Pooling(data=f, name=\"pool\"+str(level+1), pool_type=\"max\", kernel=(2, 2),stride=(2, 2))\n",
    "\n",
    "    return f\n",
    "\n",
    "def get_pcalayer(X,level,layer,num_filters):\n",
    "    cols = get_patches(X,(pks,pks))\n",
    "    nk = num_filters[level]\n",
    "    evals, evecs = PCA(cols, r, nk)\n",
    "    weights = np.zeros((nk,X.shape[1],pks,pks))\n",
    "    for n in range(nk):\n",
    "        weights[n,:,:,:]= np.reshape(evecs[:,n],(X.shape[1],pks,pks))\n",
    "    return mx.nd.array(weights)\n",
    "\n",
    "def get_pcadata_net(clevel=0,clayer=0, ks = ks, pks = pks,num_filters1=num_filters1,num_filters2=num_filters2):\n",
    "    hks = int((ks-1)/2)\n",
    "    hpks = int((pks-1)/2)\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "    for l in range(clevel+1):\n",
    "        num_filter1 = num_filters1[l]\n",
    "        num_filter2 = num_filters2[l]\n",
    "        layers = num_layers[l]\n",
    "        if l<clevel:\n",
    "            for layer in range(layers):\n",
    "                data = get_block(data=data,level=l+1,layer=layer+1,num_filter1=num_filter1,num_filter2=num_filter2,ks=ks,hks=hks,pks=pks,hpks=hpks)\n",
    "            data = mx.sym.Pooling(data=data, name=\"pool\"+str(l+1), pool_type=\"max\", kernel=(2, 2),stride=(2, 2))\n",
    "        else:\n",
    "            if clayer > 0:\n",
    "                for layer in range(clayer):\n",
    "                    data = get_block(data=data,level=l+1,layer=layer+1,num_filter1=num_filter1,num_filter2=num_filter2,ks=ks,hks=hks,pks=pks,hpks=hpks)\n",
    "            out = mx.sym.Convolution(data=data,name=\"pca\"+str(clevel+1)+str(clayer+1), kernel=(pks,pks), pad=(hpks,hpks), num_filter = num_filter1, no_bias=True)\n",
    "    return out\n",
    "    \n",
    "def training_layer(num_classes=10, level=1, layer=1, num_filter2=16, bnmomentum = momentum,pool_kernel=(2,2)):\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "    data = mx.symbol.Convolution(data=data,name=\"alpha\"+str(level)+str(layer), kernel=(1,1), pad=(0,0), num_filter=num_filter2)\n",
    "    data = mx.symbol.BatchNorm(data=data,name=\"bn\"+str(level)+str(layer), fix_gamma=False, momentum=bnmomentum, eps=2e-5)\n",
    "    data = mx.symbol.Activation(data=data, act_type=\"relu\", name=\"relu\"+str(level)+str(layer))\n",
    "    data = mx.symbol.Pooling(data=data, kernel=pool_kernel,stride = pool_kernel, pool_type='avg')\n",
    "    #data = mx.symbol.Pooling(data=data,kernel=pool_kernel, global_pool = 'True', pool_type='avg')\n",
    "    data = mx.symbol.Flatten(data=data)\n",
    "    data = mx.symbol.FullyConnected(data=data, num_hidden=num_classes, name='fc')\n",
    "    softmax = mx.symbol.SoftmaxOutput(data=data, name='softmax')    \n",
    "    return softmax\n",
    "                                 \n",
    "     \n",
    "        \n",
    "acc = mx.metric.Accuracy()      \n",
    "        \n",
    "(train, val) = get_iterator(data_dir, batch_size)\n",
    "        \n",
    "train_pca = mx.io.ImageRecordIter(\n",
    "        path_imgrec=data_dir + 'train.rec',\n",
    "        batch_size=10000,\n",
    "        rand_crop=False,\n",
    "        rand_mirror=False,\n",
    "        pad=4,\n",
    "        fill_value=127,\n",
    "        shuffle=False,\n",
    "        data_shape=(3, 32, 32)\n",
    ")\n",
    "ctx = mx.gpu()\n",
    "X_pca = mx.nd.zeros((num_train,3,32,32))\n",
    "X_pca = mx.nd.zeros((20000,3,32,32))\n",
    "i = 0\n",
    "\n",
    "for batch in train_pca:\n",
    "    batch_data = batch.data[0]\n",
    "    length = batch_data.shape[0]\n",
    "    if i+length <= X_pca.shape[0]:\n",
    "        X_pca[i:length+i,:,:,:] = batch_data\n",
    "        i = i+length\n",
    "        print i, batch_data.shape\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "plks =  32/(2**(num_levels-1))  \n",
    "pool_kernel = (plks,plks)\n",
    "#pca_kernels = get_pcalayer(X_pca,0,0,num_filters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training at level= 0, layer= 0\n",
      "The ratio of the first 8 eigenvalues is 0.953596\n",
      "Got pca kernels, shape: (8L, 3L, 3L, 3L)\n",
      "epoch = 0, tacc = 0.247540, vacc = 0.000000\n",
      "epoch = 1, tacc = 0.275480, vacc = 0.000000\n",
      "epoch = 2, tacc = 0.293000, vacc = 0.000000\n",
      "epoch = 3, tacc = 0.306195, vacc = 0.000000\n",
      "epoch = 4, tacc = 0.316520, vacc = 0.000000\n",
      "epoch = 5, tacc = 0.324433, vacc = 0.000000\n",
      "epoch = 6, tacc = 0.330526, vacc = 0.000000\n",
      "epoch = 7, tacc = 0.335800, vacc = 0.000000\n",
      "epoch = 8, tacc = 0.341018, vacc = 0.000000\n",
      "epoch = 9, tacc = 0.346186, vacc = 0.000000\n",
      "epoch = 10, tacc = 0.351316, vacc = 0.000000\n",
      "epoch = 11, tacc = 0.355640, vacc = 0.000000\n",
      "epoch = 12, tacc = 0.359657, vacc = 0.000000\n",
      "epoch = 13, tacc = 0.363277, vacc = 0.000000\n",
      "epoch = 14, tacc = 0.366604, vacc = 0.000000\n",
      "epoch = 15, tacc = 0.369463, vacc = 0.000000\n",
      "epoch = 16, tacc = 0.372053, vacc = 0.000000\n",
      "epoch = 17, tacc = 0.374687, vacc = 0.000000\n",
      "epoch = 18, tacc = 0.377006, vacc = 0.000000\n",
      "epoch = 19, tacc = 0.379074, vacc = 0.000000\n",
      "epoch = 20, tacc = 0.381219, vacc = 0.000000\n",
      "epoch = 21, tacc = 0.383211, vacc = 0.000000\n",
      "epoch = 22, tacc = 0.385036, vacc = 0.000000\n",
      "epoch = 23, tacc = 0.386729, vacc = 0.000000\n",
      "epoch = 24, tacc = 0.388487, vacc = 0.000000\n",
      "epoch = 25, tacc = 0.389992, vacc = 0.000000\n",
      "epoch = 26, tacc = 0.391513, vacc = 0.000000\n",
      "epoch = 27, tacc = 0.392987, vacc = 0.000000\n",
      "epoch = 28, tacc = 0.394344, vacc = 0.000000\n",
      "epoch = 29, tacc = 0.395667, vacc = 0.000000\n",
      "epoch = 30, tacc = 0.396850, vacc = 0.000000\n",
      "epoch = 31, tacc = 0.398066, vacc = 0.000000\n",
      "epoch = 32, tacc = 0.399218, vacc = 0.000000\n",
      "epoch = 33, tacc = 0.400364, vacc = 0.000000\n",
      "epoch = 34, tacc = 0.401490, vacc = 0.000000\n",
      "epoch = 35, tacc = 0.402527, vacc = 0.000000\n",
      "epoch = 36, tacc = 0.403490, vacc = 0.000000\n",
      "epoch = 37, tacc = 0.404490, vacc = 0.000000\n",
      "epoch = 38, tacc = 0.405405, vacc = 0.000000\n",
      "epoch = 39, tacc = 0.406267, vacc = 0.000000\n",
      "epoch = 40, tacc = 0.407066, vacc = 0.000000\n",
      "epoch = 41, tacc = 0.407896, vacc = 0.000000\n",
      "epoch = 42, tacc = 0.408548, vacc = 0.000000\n",
      "epoch = 43, tacc = 0.409325, vacc = 0.000000\n",
      "epoch = 44, tacc = 0.410086, vacc = 0.000000\n",
      "epoch = 45, tacc = 0.410804, vacc = 0.000000\n",
      "epoch = 46, tacc = 0.411498, vacc = 0.000000\n",
      "epoch = 47, tacc = 0.412107, vacc = 0.000000\n",
      "epoch = 48, tacc = 0.412775, vacc = 0.000000\n",
      "epoch = 49, tacc = 0.413446, vacc = 0.000000\n",
      "fc_bias (10L,) (10L,)\n",
      "bn11_gamma (16L,) (16L,)\n",
      "fc_weight (10L, 64L) (10L, 16L)\n",
      "alpha11_weight (16L, 8L, 1L, 1L) (16L, 8L, 1L, 1L)\n",
      "bn11_beta (16L,) (16L,)\n",
      "alpha11_bias (16L,) (16L,)\n",
      "Xpcashape: (20000L, 3L, 32L, 32L)\n",
      "f_out: <NDArray 20000x16x16x16 @gpu(0)>\n",
      "Got feature maps, shape: (20000L, 16L, 16L, 16L)\n",
      "start training at level= 1, layer= 0\n",
      "The ratio of the first 40 eigenvalues is 0.925246\n",
      "Got pca kernels, shape: (40L, 16L, 3L, 3L)\n",
      "epoch = 0, tacc = 0.411180, vacc = 0.000000\n",
      "epoch = 1, tacc = 0.410632, vacc = 0.000000\n",
      "epoch = 2, tacc = 0.410686, vacc = 0.000000\n",
      "epoch = 3, tacc = 0.411066, vacc = 0.000000\n",
      "epoch = 4, tacc = 0.411668, vacc = 0.000000\n",
      "epoch = 5, tacc = 0.412385, vacc = 0.000000\n",
      "epoch = 6, tacc = 0.413217, vacc = 0.000000\n",
      "epoch = 7, tacc = 0.414114, vacc = 0.000000\n",
      "epoch = 8, tacc = 0.415126, vacc = 0.000000\n",
      "epoch = 9, tacc = 0.416116, vacc = 0.000000\n",
      "epoch = 10, tacc = 0.417168, vacc = 0.000000\n",
      "epoch = 11, tacc = 0.418245, vacc = 0.000000\n",
      "epoch = 12, tacc = 0.419344, vacc = 0.000000\n",
      "epoch = 13, tacc = 0.420487, vacc = 0.000000\n",
      "epoch = 14, tacc = 0.421646, vacc = 0.000000\n",
      "epoch = 15, tacc = 0.422770, vacc = 0.000000\n",
      "epoch = 16, tacc = 0.423900, vacc = 0.000000\n",
      "epoch = 17, tacc = 0.425048, vacc = 0.000000\n",
      "epoch = 18, tacc = 0.426210, vacc = 0.000000\n",
      "epoch = 19, tacc = 0.427337, vacc = 0.000000\n",
      "epoch = 20, tacc = 0.428469, vacc = 0.000000\n",
      "epoch = 21, tacc = 0.429586, vacc = 0.000000\n",
      "epoch = 22, tacc = 0.430705, vacc = 0.000000\n",
      "epoch = 23, tacc = 0.431761, vacc = 0.000000\n",
      "epoch = 24, tacc = 0.432874, vacc = 0.000000\n",
      "epoch = 25, tacc = 0.433919, vacc = 0.000000\n",
      "epoch = 26, tacc = 0.434997, vacc = 0.000000\n",
      "epoch = 27, tacc = 0.436025, vacc = 0.000000\n",
      "epoch = 28, tacc = 0.437043, vacc = 0.000000\n",
      "epoch = 29, tacc = 0.438056, vacc = 0.000000\n",
      "epoch = 30, tacc = 0.439082, vacc = 0.000000\n",
      "epoch = 31, tacc = 0.440072, vacc = 0.000000\n",
      "epoch = 32, tacc = 0.441040, vacc = 0.000000\n",
      "epoch = 33, tacc = 0.442007, vacc = 0.000000\n",
      "epoch = 34, tacc = 0.442966, vacc = 0.000000\n",
      "epoch = 35, tacc = 0.443889, vacc = 0.000000\n",
      "epoch = 36, tacc = 0.444820, vacc = 0.000000\n",
      "epoch = 37, tacc = 0.445732, vacc = 0.000000\n",
      "epoch = 38, tacc = 0.446610, vacc = 0.000000\n",
      "epoch = 39, tacc = 0.447487, vacc = 0.000000\n",
      "epoch = 40, tacc = 0.448355, vacc = 0.000000\n",
      "epoch = 41, tacc = 0.449188, vacc = 0.000000\n",
      "epoch = 42, tacc = 0.450039, vacc = 0.000000\n",
      "epoch = 43, tacc = 0.450864, vacc = 0.000000\n",
      "epoch = 44, tacc = 0.451681, vacc = 0.000000\n",
      "epoch = 45, tacc = 0.452473, vacc = 0.000000\n",
      "epoch = 46, tacc = 0.453251, vacc = 0.000000\n",
      "epoch = 47, tacc = 0.454005, vacc = 0.000000\n",
      "epoch = 48, tacc = 0.454785, vacc = 0.000000\n",
      "epoch = 49, tacc = 0.455528, vacc = 0.000000\n",
      "alpha21_weight (32L, 40L, 1L, 1L) (32L, 40L, 1L, 1L)\n",
      "fc_bias (10L,) (10L,)\n",
      "alpha21_bias (32L,) (32L,)\n",
      "fc_weight (10L, 64L) (10L, 32L)\n",
      "bn21_gamma (32L,) (32L,)\n",
      "bn21_beta (32L,) (32L,)\n",
      "Xpcashape: (20000L, 16L, 16L, 16L)\n",
      "f_out: <NDArray 20000x32x16x16 @gpu(0)>\n",
      "Got feature maps, shape: (20000L, 32L, 16L, 16L)\n",
      "start training at level= 1, layer= 1\n",
      "The ratio of the first 40 eigenvalues is 0.766592\n",
      "Got pca kernels, shape: (40L, 32L, 3L, 3L)\n",
      "epoch = 0, tacc = 0.453569, vacc = 0.000000\n",
      "epoch = 1, tacc = 0.452231, vacc = 0.000000\n",
      "epoch = 2, tacc = 0.451354, vacc = 0.000000\n",
      "epoch = 3, tacc = 0.450697, vacc = 0.000000\n",
      "epoch = 4, tacc = 0.450198, vacc = 0.000000\n",
      "epoch = 5, tacc = 0.449821, vacc = 0.000000\n",
      "epoch = 6, tacc = 0.449531, vacc = 0.000000\n",
      "epoch = 7, tacc = 0.449322, vacc = 0.000000\n",
      "epoch = 8, tacc = 0.449191, vacc = 0.000000\n",
      "epoch = 9, tacc = 0.449090, vacc = 0.000000\n",
      "epoch = 10, tacc = 0.449046, vacc = 0.000000\n",
      "epoch = 11, tacc = 0.449057, vacc = 0.000000\n",
      "epoch = 12, tacc = 0.449104, vacc = 0.000000\n",
      "epoch = 13, tacc = 0.449187, vacc = 0.000000\n",
      "epoch = 14, tacc = 0.449313, vacc = 0.000000\n",
      "epoch = 15, tacc = 0.449449, vacc = 0.000000\n",
      "epoch = 16, tacc = 0.449605, vacc = 0.000000\n",
      "epoch = 17, tacc = 0.449788, vacc = 0.000000\n",
      "epoch = 18, tacc = 0.449982, vacc = 0.000000\n",
      "epoch = 19, tacc = 0.450197, vacc = 0.000000\n",
      "epoch = 20, tacc = 0.450429, vacc = 0.000000\n",
      "epoch = 21, tacc = 0.450674, vacc = 0.000000\n",
      "epoch = 22, tacc = 0.450920, vacc = 0.000000\n",
      "epoch = 23, tacc = 0.451184, vacc = 0.000000\n",
      "epoch = 24, tacc = 0.451445, vacc = 0.000000\n",
      "epoch = 25, tacc = 0.451721, vacc = 0.000000\n",
      "epoch = 26, tacc = 0.451996, vacc = 0.000000\n",
      "epoch = 27, tacc = 0.452298, vacc = 0.000000\n",
      "epoch = 28, tacc = 0.452569, vacc = 0.000000\n",
      "epoch = 29, tacc = 0.452842, vacc = 0.000000\n",
      "epoch = 30, tacc = 0.453123, vacc = 0.000000\n",
      "epoch = 31, tacc = 0.453407, vacc = 0.000000\n",
      "epoch = 32, tacc = 0.453701, vacc = 0.000000\n",
      "epoch = 33, tacc = 0.453979, vacc = 0.000000\n",
      "epoch = 34, tacc = 0.454265, vacc = 0.000000\n",
      "epoch = 35, tacc = 0.454532, vacc = 0.000000\n",
      "epoch = 36, tacc = 0.454806, vacc = 0.000000\n",
      "epoch = 37, tacc = 0.455108, vacc = 0.000000\n",
      "epoch = 38, tacc = 0.455389, vacc = 0.000000\n",
      "epoch = 39, tacc = 0.455651, vacc = 0.000000\n",
      "epoch = 40, tacc = 0.455951, vacc = 0.000000\n",
      "epoch = 41, tacc = 0.456235, vacc = 0.000000\n",
      "epoch = 42, tacc = 0.456512, vacc = 0.000000\n",
      "epoch = 43, tacc = 0.456787, vacc = 0.000000\n",
      "epoch = 44, tacc = 0.457059, vacc = 0.000000\n",
      "epoch = 45, tacc = 0.457336, vacc = 0.000000\n",
      "epoch = 46, tacc = 0.457606, vacc = 0.000000\n",
      "epoch = 47, tacc = 0.457874, vacc = 0.000000\n",
      "epoch = 48, tacc = 0.458137, vacc = 0.000000\n",
      "epoch = 49, tacc = 0.458403, vacc = 0.000000\n",
      "fc_bias (10L,) (10L,)\n",
      "alpha22_bias (32L,) (32L,)\n",
      "bn22_gamma (32L,) (32L,)\n",
      "alpha22_weight (32L, 40L, 1L, 1L) (32L, 40L, 1L, 1L)\n",
      "bn22_beta (32L,) (32L,)\n",
      "fc_weight (10L, 64L) (10L, 32L)\n",
      "Xpcashape: (20000L, 32L, 16L, 16L)\n",
      "f_out: <NDArray 20000x32x8x8 @gpu(0)>\n",
      "Got feature maps, shape: (20000L, 32L, 8L, 8L)\n",
      "start training at level= 2, layer= 0\n",
      "The ratio of the first 128 eigenvalues is 0.984636\n",
      "Got pca kernels, shape: (128L, 32L, 3L, 3L)\n",
      "epoch = 0, tacc = 0.456961, vacc = 0.000000\n",
      "epoch = 1, tacc = 0.456457, vacc = 0.000000\n",
      "epoch = 2, tacc = 0.456041, vacc = 0.000000\n",
      "epoch = 3, tacc = 0.455625, vacc = 0.000000\n",
      "epoch = 4, tacc = 0.455201, vacc = 0.000000\n",
      "epoch = 5, tacc = 0.454783, vacc = 0.000000\n",
      "epoch = 6, tacc = 0.454391, vacc = 0.000000\n",
      "epoch = 7, tacc = 0.454017, vacc = 0.000000\n",
      "epoch = 8, tacc = 0.453684, vacc = 0.000000\n",
      "epoch = 9, tacc = 0.453396, vacc = 0.000000\n",
      "epoch = 10, tacc = 0.453119, vacc = 0.000000\n",
      "epoch = 11, tacc = 0.452878, vacc = 0.000000\n",
      "epoch = 12, tacc = 0.452649, vacc = 0.000000\n",
      "epoch = 13, tacc = 0.452449, vacc = 0.000000\n",
      "epoch = 14, tacc = 0.452280, vacc = 0.000000\n",
      "epoch = 15, tacc = 0.452149, vacc = 0.000000\n",
      "epoch = 16, tacc = 0.452023, vacc = 0.000000\n",
      "epoch = 17, tacc = 0.451919, vacc = 0.000000\n",
      "epoch = 18, tacc = 0.451825, vacc = 0.000000\n",
      "epoch = 19, tacc = 0.451754, vacc = 0.000000\n",
      "epoch = 20, tacc = 0.451691, vacc = 0.000000\n",
      "epoch = 21, tacc = 0.451638, vacc = 0.000000\n",
      "epoch = 22, tacc = 0.451604, vacc = 0.000000\n",
      "epoch = 23, tacc = 0.451586, vacc = 0.000000\n",
      "epoch = 24, tacc = 0.451576, vacc = 0.000000\n",
      "epoch = 25, tacc = 0.451574, vacc = 0.000000\n",
      "epoch = 26, tacc = 0.451579, vacc = 0.000000\n",
      "epoch = 27, tacc = 0.451576, vacc = 0.000000\n",
      "epoch = 28, tacc = 0.451593, vacc = 0.000000\n",
      "epoch = 29, tacc = 0.451612, vacc = 0.000000\n",
      "epoch = 30, tacc = 0.451643, vacc = 0.000000\n",
      "epoch = 31, tacc = 0.451678, vacc = 0.000000\n",
      "epoch = 32, tacc = 0.451718, vacc = 0.000000\n",
      "epoch = 33, tacc = 0.451752, vacc = 0.000000\n",
      "epoch = 34, tacc = 0.451799, vacc = 0.000000\n",
      "epoch = 35, tacc = 0.451837, vacc = 0.000000\n",
      "epoch = 36, tacc = 0.451890, vacc = 0.000000\n",
      "epoch = 37, tacc = 0.451954, vacc = 0.000000\n",
      "epoch = 38, tacc = 0.452021, vacc = 0.000000\n",
      "epoch = 39, tacc = 0.452073, vacc = 0.000000\n",
      "epoch = 40, tacc = 0.452134, vacc = 0.000000\n",
      "epoch = 41, tacc = 0.452211, vacc = 0.000000\n",
      "epoch = 42, tacc = 0.452270, vacc = 0.000000\n",
      "epoch = 43, tacc = 0.452341, vacc = 0.000000\n",
      "epoch = 44, tacc = 0.452421, vacc = 0.000000\n",
      "epoch = 45, tacc = 0.452500, vacc = 0.000000\n",
      "epoch = 46, tacc = 0.452570, vacc = 0.000000\n",
      "epoch = 47, tacc = 0.452651, vacc = 0.000000\n",
      "epoch = 48, tacc = 0.452738, vacc = 0.000000\n",
      "epoch = 49, tacc = 0.452825, vacc = 0.000000\n",
      "alpha31_weight (64L, 128L, 1L, 1L) (64L, 128L, 1L, 1L)\n",
      "alpha31_bias (64L,) (64L,)\n",
      "bn31_beta (64L,) (64L,)\n",
      "fc_weight (10L, 64L) (10L, 64L)\n",
      "fc_bias (10L,) (10L,)\n",
      "bn31_gamma (64L,) (64L,)\n",
      "Xpcashape: (20000L, 32L, 8L, 8L)\n",
      "f_out: <NDArray 20000x64x8x8 @gpu(0)>\n",
      "Got feature maps, shape: (20000L, 64L, 8L, 8L)\n",
      "start training at level= 2, layer= 1\n",
      "The ratio of the first 128 eigenvalues is 0.981687\n",
      "Got pca kernels, shape: (128L, 64L, 3L, 3L)\n",
      "epoch = 0, tacc = 0.451033, vacc = 0.000000\n",
      "epoch = 1, tacc = 0.449959, vacc = 0.000000\n",
      "epoch = 2, tacc = 0.449280, vacc = 0.000000\n",
      "epoch = 3, tacc = 0.448711, vacc = 0.000000\n",
      "epoch = 4, tacc = 0.448244, vacc = 0.000000\n",
      "epoch = 5, tacc = 0.447871, vacc = 0.000000\n",
      "epoch = 6, tacc = 0.447584, vacc = 0.000000\n",
      "epoch = 7, tacc = 0.447343, vacc = 0.000000\n",
      "epoch = 8, tacc = 0.447140, vacc = 0.000000\n",
      "epoch = 9, tacc = 0.446958, vacc = 0.000000\n",
      "epoch = 10, tacc = 0.446802, vacc = 0.000000\n",
      "epoch = 11, tacc = 0.446662, vacc = 0.000000\n",
      "epoch = 12, tacc = 0.446533, vacc = 0.000000\n",
      "epoch = 13, tacc = 0.446401, vacc = 0.000000\n",
      "epoch = 14, tacc = 0.446273, vacc = 0.000000\n",
      "epoch = 15, tacc = 0.446161, vacc = 0.000000\n",
      "epoch = 16, tacc = 0.446038, vacc = 0.000000\n",
      "epoch = 17, tacc = 0.445935, vacc = 0.000000\n",
      "epoch = 18, tacc = 0.445823, vacc = 0.000000\n",
      "epoch = 19, tacc = 0.445719, vacc = 0.000000\n",
      "epoch = 20, tacc = 0.445611, vacc = 0.000000\n",
      "epoch = 21, tacc = 0.445517, vacc = 0.000000\n",
      "epoch = 22, tacc = 0.445413, vacc = 0.000000\n",
      "epoch = 23, tacc = 0.445320, vacc = 0.000000\n",
      "epoch = 24, tacc = 0.445225, vacc = 0.000000\n",
      "epoch = 25, tacc = 0.445125, vacc = 0.000000\n",
      "epoch = 26, tacc = 0.445032, vacc = 0.000000\n",
      "epoch = 27, tacc = 0.444940, vacc = 0.000000\n",
      "epoch = 28, tacc = 0.444854, vacc = 0.000000\n",
      "epoch = 29, tacc = 0.444764, vacc = 0.000000\n",
      "epoch = 30, tacc = 0.444675, vacc = 0.000000\n",
      "epoch = 31, tacc = 0.444593, vacc = 0.000000\n",
      "epoch = 32, tacc = 0.444511, vacc = 0.000000\n",
      "epoch = 33, tacc = 0.444426, vacc = 0.000000\n",
      "epoch = 34, tacc = 0.444340, vacc = 0.000000\n",
      "epoch = 35, tacc = 0.444259, vacc = 0.000000\n",
      "epoch = 36, tacc = 0.444179, vacc = 0.000000\n",
      "epoch = 37, tacc = 0.444100, vacc = 0.000000\n",
      "epoch = 38, tacc = 0.444024, vacc = 0.000000\n",
      "epoch = 39, tacc = 0.443941, vacc = 0.000000\n",
      "epoch = 40, tacc = 0.443863, vacc = 0.000000\n",
      "epoch = 41, tacc = 0.443790, vacc = 0.000000\n",
      "epoch = 42, tacc = 0.443716, vacc = 0.000000\n",
      "epoch = 43, tacc = 0.443646, vacc = 0.000000\n",
      "epoch = 44, tacc = 0.443570, vacc = 0.000000\n",
      "epoch = 45, tacc = 0.443502, vacc = 0.000000\n",
      "epoch = 46, tacc = 0.443423, vacc = 0.000000\n",
      "epoch = 47, tacc = 0.443345, vacc = 0.000000\n",
      "epoch = 48, tacc = 0.443270, vacc = 0.000000\n",
      "epoch = 49, tacc = 0.443202, vacc = 0.000000\n",
      "fc_bias (10L,) (10L,)\n",
      "bn32_beta (64L,) (64L,)\n",
      "alpha32_weight (64L, 128L, 1L, 1L) (64L, 128L, 1L, 1L)\n",
      "bn32_gamma (64L,) (64L,)\n",
      "fc_weight (10L, 64L) (10L, 64L)\n",
      "alpha32_bias (64L,) (64L,)\n",
      "Xpcashape: (20000L, 64L, 8L, 8L)\n",
      "f_out: <NDArray 20000x64x4x4 @gpu(0)>\n",
      "Got feature maps, shape: (20000L, 64L, 4L, 4L)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-14 17:42:12.046811. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random = 0\n",
    "\n",
    "\n",
    "\n",
    "network = get_net(num_classes=10,num_filters1=num_filters1,num_filters2=num_filters2,num_levels=num_levels,num_layers=num_layers,ks=ks, pks=pks, pool_kernel = pool_kernel, lr_mult=0.0)\n",
    "\n",
    "mod = mx.mod.Module(symbol=network, context=devs)\n",
    "mod.bind(data_shapes=train.provide_data,label_shapes=train.provide_label, force_rebind=True)\n",
    "mod.init_params(initializer=mx.init.Xavier(magnitude=0.01))\n",
    "arg_params,aux_params =  mod.get_params()\n",
    "\n",
    "#vis = mx.viz.plot_network(network, shape={\"data\":(64, 3, 32, 32)}, node_attrs={\"shape\":'rect',\"fixedsize\":'false'})\n",
    "#vis.render('gpcanet'+ str(num_conv))\n",
    "\n",
    "#print weights.asnumpy().flatten()\n",
    "#print args_all['alpha11_weight'].asnumpy().flatten()\n",
    "#print args_all['pca11_weight'].asnumpy()[0,:,:,:]\n",
    "#print train_list\n",
    "\n",
    "wd = 0\n",
    "FactorScheduler = mx.lr_scheduler.FactorScheduler(epoch_size,factor)\n",
    "opt = mx.optimizer.SGD(learning_rate=learning_rate,\n",
    "                       momentum=0.9,wd=wd,\n",
    "                       lr_scheduler=FactorScheduler,\n",
    "                       rescale_grad=1.0/batch_size)\n",
    "\n",
    "\n",
    "we = arg_params['fc_weight'].copy()\n",
    "metric = mx.metric.create('acc')\n",
    "\n",
    "for clevel in range(num_levels):\n",
    "    layers = num_layers[clevel]\n",
    "    pooling = False\n",
    "    num_filter1 = num_filters1[clevel]\n",
    "    num_filter2 = num_filters2[clevel]\n",
    "    \n",
    "    num_filter2 = num_filters2[clevel]\n",
    "    ratio = num_filters2[-1]/num_filter2\n",
    "    #plks =  32/(2**(num_levels-clevel-1))  \n",
    "    plks = 32/2**clevel\n",
    "    pool_kernel = (plks,plks)\n",
    "    \n",
    "    for clayer in range(layers):\n",
    "        print 'start training at level= %d, layer= %d' %(clevel,clayer)\n",
    "        # get pca kernels\n",
    "        pca_kernels = []\n",
    "        if random == 1:\n",
    "            nk = num_filters1[clevel]\n",
    "            nc = num_filters2[clevel]\n",
    "            pcashape = (nk,X_pca.shape[1], ks,ks)\n",
    "            pca_kernels = mx.nd.normal(scale = 1, shape = pcashape)\n",
    "        else:\n",
    "            pca_kernels = get_pcalayer(X_pca,clevel,clayer,num_filters1)\n",
    "        print 'Got pca kernels, shape:', pca_kernels.shape \n",
    "        # get mod for the pca trainning data \n",
    "        key = \"pca\"+str(clevel+1)+str(clayer+1)+\"_weight\"\n",
    "        arg_params[key][:] = pca_kernels\n",
    "        \n",
    "        pcadata_net = get_pcadata_net(clevel=clevel,clayer = clayer)\n",
    "        mod1 = None\n",
    "        mod1 = mx.mod.Module(symbol=pcadata_net, context=devs)\n",
    "        mod1.bind(data_shapes=train.provide_data,for_training=False,force_rebind=True) \n",
    "        mod1.init_params(initializer=mx.init.Xavier(magnitude=0.01))\n",
    "        arg_params1,aux_params1 =  mod1.get_params()\n",
    "        for key, weight in arg_params1.items():\n",
    "            weight[:] = arg_params[key]\n",
    "        for key, weight in aux_params1.items():\n",
    "            weight[:] = aux_params[key]\n",
    "        mod1.set_params(arg_params = arg_params1, aux_params=aux_params1) \n",
    "        name, output_shape = mod1.output_shapes[0]\n",
    "        data_shape =  [mx.io.DataDesc(name = 'data', shape = output_shape,layout='NCHW')]\n",
    "        # pool_kernel = ()\n",
    "        # training\n",
    "        training_net = training_layer(num_classes=10, level=clevel+1,layer=clayer+1, \n",
    "                                      num_filter2=num_filter2, bnmomentum = momentum,pool_kernel=pool_kernel)\n",
    "        mod2 = None\n",
    "        mod2 = mx.mod.Module(symbol=training_net, context=devs) \n",
    "        mod2.bind(data_shapes=data_shape, label_shapes=train.provide_label,force_rebind=True)\n",
    "        mod2.init_params(initializer=mx.init.Xavier(magnitude=0.01))\n",
    "        mod2.init_optimizer(optimizer=opt, force_init=False) \n",
    "        for epoch in range(num_epoch):\n",
    "            train.reset()\n",
    "            val.reset()\n",
    "            for batch in train:\n",
    "                mod1.forward(batch,is_train=False)\n",
    "                outputs = mod1.get_outputs()\n",
    "                databatch = mx.io.DataBatch(data=outputs, label=batch.label)     \n",
    "                mod2.forward(databatch, is_train=True)       \n",
    "                mod2.update_metric(metric, batch.label)  \n",
    "                mod2.backward()                           \n",
    "                mod2.update()\n",
    "            _,tacc = metric.get()\n",
    "            vacc = 0\n",
    "            '''\n",
    "            for batch in val:\n",
    "                mod1.forward(batch,is_train=False)\n",
    "                outputs = mod1.get_outputs()\n",
    "                databatch = mx.io.DataBatch(data=outputs, label=batch.label)     \n",
    "                mod2.forward(databatch, is_train=False)       \n",
    "                mod2.update_metric(metric, batch.label)  \n",
    "            _,vacc = metric.get() '''\n",
    "            print 'epoch = %d, tacc = %f, vacc = %f' %(epoch, tacc, vacc)\n",
    "        # get pca kernels\n",
    "        arg_params2, aux_params2 = mod2.get_params()\n",
    "        for key, weight in arg_params2.items():\n",
    "            print key, arg_params[key].shape, weight.shape\n",
    "            if 'fc' not in key:\n",
    "                arg_params[key][:] = weight\n",
    "        for key, weight in aux_params2.items():\n",
    "            aux_params[key][:] = weight\n",
    "        if  clayer==layers-1:\n",
    "            pooling = True\n",
    "        print 'Xpcashape:',X_pca.shape\n",
    "        X_pca = layer_forward(mx.gpu(), X_pca, arg_params,aux_params,clevel,clayer,\n",
    "                          num_filter1,num_filter2,ks,hks,pks,hpks,momentum=momentum,pooling=pooling)\n",
    "        print 'Got feature maps, shape:', X_pca.shape\n",
    "        \n",
    "            #print arg_layer['fc_weight'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint X_train.shape    \\nind = 1\\ny = Y_train.asnumpy();\\nprint y[ind]\\nimg = X_train.asnumpy()[ind,:,:,:]\\nimg = img.transpose(1,2,0)\\nimg = np.flipud(img)\\ndpi = 20\\nfigsize = (32/dpi,32/dpi)\\nfig = plt.figure(figsize=figsize)\\nimgplot = plt.imshow(np.reshape(np.uint8(img),(32,32,3)))\\nplt.axis('off')\\nplt.show()\\nind = 1\\nx = val.getdata()\\ny = val.getlabel().asnumpy()\\nprint y[ind]\\n\\nimg = x.asnumpy()[ind,:,:,:]\\nimg = img.transpose(1,2,0)\\nimg = np.flipud(img)\\nfigsize = (32/dpi,32/dpi)\\nfig = plt.figure(figsize=figsize)\\nimgplot = plt.imshow(np.reshape(np.uint8(img),(32,32,3)))\\nplt.axis('off')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-04-14 17:52:07.139196. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print X_train.shape    \n",
    "ind = 1\n",
    "y = Y_train.asnumpy();\n",
    "print y[ind]\n",
    "img = X_train.asnumpy()[ind,:,:,:]\n",
    "img = img.transpose(1,2,0)\n",
    "img = np.flipud(img)\n",
    "dpi = 20\n",
    "figsize = (32/dpi,32/dpi)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "imgplot = plt.imshow(np.reshape(np.uint8(img),(32,32,3)))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "ind = 1\n",
    "x = val.getdata()\n",
    "y = val.getlabel().asnumpy()\n",
    "print y[ind]\n",
    "\n",
    "img = x.asnumpy()[ind,:,:,:]\n",
    "img = img.transpose(1,2,0)\n",
    "img = np.flipud(img)\n",
    "figsize = (32/dpi,32/dpi)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "imgplot = plt.imshow(np.reshape(np.uint8(img),(32,32,3)))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
