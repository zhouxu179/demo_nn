{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks with minpy+mxnet\n",
    "\n",
    "In this notebook, we show how to implement a CNN with minpy and mxnet. Your job is to design the forward model and train the parameters. Note that the convolution layers are efficiently implemented by using mxnet symbols.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"import dependencies\"\"\"\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import minpy\n",
    "import minpy.numpy as np\n",
    "import mxnet as mx\n",
    "from minpy.nn.io import NDArrayIter\n",
    "# Can also use MXNet IO here\n",
    "# from mxnet.io import NDArrayIter\n",
    "from minpy.core import Function\n",
    "from minpy.nn import layers\n",
    "from minpy.nn.model import ModelBase\n",
    "from minpy.nn.solver import Solver\n",
    "from data_utils import get_CIFAR10_data\n",
    "\n",
    "# Please uncomment following if you have GPU-enabled MXNet installed.\n",
    "#from minpy.context import set_context, gpu\n",
    "#set_context(gpu(0)) # set the global context as gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=(3, 32, 32)\n",
    "flattened_input_size=3 * 32 * 32\n",
    "data_dir = '/cifar-10-batches-py'\n",
    "data = get_CIFAR10_data(data_dir)\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: ajust the following parameters to obtain the best performance\n",
    "batch_size=128\n",
    "hidden_size=1024\n",
    "reg = 0.001\n",
    "num_filter = 128\n",
    "ks = (5,5)\n",
    "num_epo = 8\n",
    "learning_rate = 2e-4\n",
    "# END TODO\n",
    "class ConvolutionNet(ModelBase):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionNet, self).__init__()\n",
    "        # TODO: Define symbols that using multiple layers of convolution and max pooling to extract better features\n",
    "        # from input image.\n",
    "        net = mx.sym.Variable(name='X')\n",
    "        \n",
    "        net = mx.sym.Convolution(\n",
    "                data=net, name='conv1', kernel=ks, num_filter=nfilter)\n",
    "        net = mx.sym.Activation(\n",
    "                data=net, act_type='relu')\n",
    "        net = mx.sym.Pooling(\n",
    "                data=net, name='pool1', pool_type='max', kernel=(2, 2),\n",
    "                stride=(2, 2))\n",
    "        \n",
    "        net = mx.sym.Convolution(\n",
    "                data=net, name='conv2', kernel=ks, num_filter=nfilter)\n",
    "        net = mx.sym.Activation(\n",
    "                data=net, act_type='relu')\n",
    "        net = mx.sym.Pooling(\n",
    "                data=net, name='pool2', pool_type='max', kernel=(2, 2),\n",
    "                stride=(2, 2))\n",
    "        # END TODO\n",
    "        net = mx.sym.Flatten(data=net)\n",
    "        \n",
    "        #Create CNN function and add parameters to the model.\n",
    "        self.conv = Function(\n",
    "                net, input_shapes={'X': (batch_size,) + input_size},\n",
    "                name='conv')\n",
    "        self.add_params(self.conv.get_params())\n",
    "        # Define ndarray parameters used for classification part.\n",
    "        output_shape = self.conv.get_one_output_shape()\n",
    "        conv_out_size = output_shape[1]\n",
    "        # TODO: add parameters of full connected layers, based on your forward model   \n",
    "        self.add_param(name='w1', shape=(conv_out_size, hidden_size)) \\\n",
    "            .add_param(name='b1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='gamma1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='beta1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='w2', shape=(hidden_size, num_classes)) \\\n",
    "            .add_param(name='b2', shape=(num_classes,))\n",
    "        # END TODO\n",
    "    def forward(self, X, mode):\n",
    "        # TODO: build your forward model\n",
    "        out = self.conv(X=X, **self.params)\n",
    "        out = layers.affine(out, self.params['w1'], self.params['b1'])\n",
    "        out = layers.relu(out)\n",
    "        out = layers.affine(out, self.params['w2'], self.params['b2'])\n",
    "        # END TODO\n",
    "        return out\n",
    "\n",
    "    def loss(self, predict, y):\n",
    "\tloss_reg = reg\n",
    "\tfor name, weight in self.params.iteritems():\n",
    "    \t    loss_reg += np.sum(weight**2)\n",
    "        return layers.softmax_loss(predict, y) + 0.5*reg*loss_reg\n",
    "\n",
    "    # Create model.\n",
    "    model = ConvolutionNet()\n",
    "    # Create data iterators for training and testing sets.\n",
    "\n",
    "    train_dataiter = NDArrayIter(data=data['X_train'],\n",
    "                                 label=data['y_train'],\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True)\n",
    "    test_dataiter = NDArrayIter(data=data['X_test'],\n",
    "                                label=data['y_test'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Train your CNN model.\n",
    "    solver = Solver(model,\n",
    "                    train_dataiter,\n",
    "                    test_dataiter,\n",
    "                    num_epochs=num_epo,\n",
    "                    init_rule='gaussian',\n",
    "                    init_config={\n",
    "                        'stdvar': 0.001\n",
    "                    },\n",
    "                    #update_rule='sgd_momentum',\n",
    "\t                #update_rule='rmsprop',\n",
    "                    update_rule ='adam', # You may also try different optimization rules\n",
    "                    optim_config={\n",
    "                        'learning_rate': learning_rate\n",
    "                    },\n",
    "                    verbose=True,\n",
    "                    print_every=20)\n",
    "    # Initialize model parameters.\n",
    "    solver.init()\n",
    "    # Train!\n",
    "    solver.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
