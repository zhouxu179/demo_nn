{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks with minpy+mxnet\n",
    "\n",
    "In this notebook, we show how to implement a CNN with minpy and mxnet. Your job is to design the forward model and train the parameters. Note that the convolution layers are efficiently implemented by using mxnet symbols. You should get more than 70% accuracy on validation dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"import dependencies\"\"\"\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import minpy\n",
    "import minpy.numpy as np\n",
    "import mxnet as mx\n",
    "from minpy.nn.io import NDArrayIter\n",
    "# Can also use MXNet IO here\n",
    "# from mxnet.io import NDArrayIter\n",
    "from minpy.core import Function\n",
    "from minpy.nn import layers\n",
    "from minpy.nn.model import ModelBase\n",
    "from minpy.nn.solver import Solver\n",
    "from data_utils import get_CIFAR10_data\n",
    "\n",
    "# Please uncomment following if you have GPU-enabled MXNet installed.\n",
    "#from minpy.context import set_context, gpu\n",
    "#set_context(gpu(0)) # set the global context as gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_size=(3, 32, 32)\n",
    "flattened_input_size=3 * 32 * 32\n",
    "# bash get_datasets.sh if you do not have the cifar10 dataset\n",
    "data_dir = './cifar-10-batches-py'\n",
    "data = get_CIFAR10_data(data_dir)\n",
    "num_classes=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: ajust the following parameters to obtain the best performance\n",
    "batch_size=128\n",
    "hidden_size=1024\n",
    "reg = 0.001\n",
    "num_filter = 128\n",
    "ks = (5,5)\n",
    "num_epo = 10\n",
    "learning_rate = 2e-4\n",
    "# END TODO\n",
    "\n",
    "\n",
    "class ConvolutionNet(ModelBase):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionNet, self).__init__()\n",
    "        # TODO: Define symbols using multiple layers of convolution and max pooling to extract better features\n",
    "        # from input image.\n",
    "        net = mx.sym.Variable(name='X')\n",
    "        \n",
    "        net = mx.sym.Convolution(\n",
    "                data=net, name='conv1', kernel=ks, num_filter=num_filter)\n",
    "        net = mx.sym.Activation(\n",
    "                data=net, act_type='relu')\n",
    "        net = mx.sym.Pooling(\n",
    "                data=net, name='pool1', pool_type='max', kernel=(2, 2),\n",
    "                stride=(2, 2))\n",
    "        \n",
    "        net = mx.sym.Convolution(\n",
    "                data=net, name='conv2', kernel=ks, num_filter=num_filter)\n",
    "        net = mx.sym.Activation(\n",
    "                data=net, act_type='relu')\n",
    "        net = mx.sym.Pooling(\n",
    "                data=net, name='pool2', pool_type='max', kernel=(2, 2),\n",
    "                stride=(2, 2))\n",
    "        # END TODO\n",
    "        net = mx.sym.Flatten(data=net)\n",
    "        \n",
    "        #Create CNN function and add parameters to the model.\n",
    "        self.conv = Function(\n",
    "                net, input_shapes={'X': (batch_size,) + input_size},\n",
    "                name='conv')\n",
    "        self.add_params(self.conv.get_params())\n",
    "        # Define ndarray parameters used for classification part.\n",
    "        output_shape = self.conv.get_one_output_shape()\n",
    "        conv_out_size = output_shape[1]\n",
    "        # TODO: add parameters of full connected layers, based on your forward model   \n",
    "        self.add_param(name='w1', shape=(conv_out_size, hidden_size)) \\\n",
    "            .add_param(name='b1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='gamma1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='beta1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='w2', shape=(hidden_size, num_classes)) \\\n",
    "            .add_param(name='b2', shape=(num_classes,))\n",
    "        # END TODO\n",
    "    def forward(self, X, mode):\n",
    "        # TODO: build your forward model\n",
    "        out = self.conv(X=X, **self.params)\n",
    "        out = layers.affine(out, self.params['w1'], self.params['b1'])\n",
    "        out = layers.relu(out)\n",
    "        out = layers.affine(out, self.params['w2'], self.params['b2'])\n",
    "        # END TODO\n",
    "        return out\n",
    "\n",
    "    def loss(self, predict, y):\n",
    "        loss_reg = reg\n",
    "        for name, weight in self.params.iteritems():\n",
    "    \t    loss_reg += np.sum(weight**2)\n",
    "        return layers.softmax_loss(predict, y) + 0.5*reg*loss_reg\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 1148) loss: 2.304477\n",
      "(Iteration 21 / 1148) loss: 2.077509\n",
      "(Iteration 41 / 1148) loss: 1.997448\n",
      "(Iteration 61 / 1148) loss: 1.969889\n",
      "(Iteration 81 / 1148) loss: 1.814104\n",
      "(Iteration 101 / 1148) loss: 1.749671\n",
      "(Iteration 121 / 1148) loss: 1.600048\n",
      "(Iteration 141 / 1148) loss: 1.509827\n",
      "(Iteration 161 / 1148) loss: 1.567641\n",
      "(Iteration 181 / 1148) loss: 1.470913\n",
      "(Iteration 201 / 1148) loss: 1.488777\n",
      "(Iteration 221 / 1148) loss: 1.490559\n",
      "(Iteration 241 / 1148) loss: 1.354200\n",
      "(Iteration 261 / 1148) loss: 1.508165\n",
      "(Iteration 281 / 1148) loss: 1.242928\n",
      "(Iteration 301 / 1148) loss: 1.434858\n",
      "(Iteration 321 / 1148) loss: 1.430913\n",
      "(Iteration 341 / 1148) loss: 1.233354\n",
      "(Iteration 361 / 1148) loss: 1.316367\n",
      "(Iteration 381 / 1148) loss: 1.198666\n",
      "(Epoch 1 / 3) train acc: 0.535156; val_acc: 0.533203\n",
      "(Iteration 401 / 1148) loss: 1.279022\n",
      "(Iteration 421 / 1148) loss: 1.055716\n",
      "(Iteration 441 / 1148) loss: 1.405368\n",
      "(Iteration 461 / 1148) loss: 1.139587\n",
      "(Iteration 481 / 1148) loss: 1.517576\n",
      "(Iteration 501 / 1148) loss: 1.168532\n",
      "(Iteration 521 / 1148) loss: 1.104632\n",
      "(Iteration 541 / 1148) loss: 1.194266\n",
      "(Iteration 561 / 1148) loss: 1.140429\n",
      "(Iteration 581 / 1148) loss: 1.076068\n",
      "(Iteration 601 / 1148) loss: 1.162391\n",
      "(Iteration 621 / 1148) loss: 1.310441\n",
      "(Iteration 641 / 1148) loss: 1.081520\n",
      "(Iteration 661 / 1148) loss: 1.083843\n",
      "(Iteration 681 / 1148) loss: 1.184858\n",
      "(Iteration 701 / 1148) loss: 1.059721\n",
      "(Iteration 721 / 1148) loss: 1.139904\n",
      "(Iteration 741 / 1148) loss: 1.038470\n",
      "(Iteration 761 / 1148) loss: 0.998646\n",
      "(Epoch 2 / 3) train acc: 0.625977; val_acc: 0.624023\n",
      "(Iteration 781 / 1148) loss: 1.086599\n",
      "(Iteration 801 / 1148) loss: 0.985788\n",
      "(Iteration 821 / 1148) loss: 1.069502\n",
      "(Iteration 841 / 1148) loss: 1.251777\n",
      "(Iteration 861 / 1148) loss: 1.143277\n",
      "(Iteration 881 / 1148) loss: 1.046997\n",
      "(Iteration 901 / 1148) loss: 0.959836\n",
      "(Iteration 921 / 1148) loss: 1.063392\n",
      "(Iteration 941 / 1148) loss: 0.880542\n",
      "(Iteration 961 / 1148) loss: 0.897974\n",
      "(Iteration 981 / 1148) loss: 0.917087\n",
      "(Iteration 1001 / 1148) loss: 0.989731\n",
      "(Iteration 1021 / 1148) loss: 0.969251\n",
      "(Iteration 1041 / 1148) loss: 0.920094\n",
      "(Iteration 1061 / 1148) loss: 0.980640\n",
      "(Iteration 1081 / 1148) loss: 0.857802\n",
      "(Iteration 1101 / 1148) loss: 0.908024\n",
      "(Iteration 1121 / 1148) loss: 0.845429\n",
      "(Iteration 1141 / 1148) loss: 0.857203\n",
      "(Epoch 3 / 3) train acc: 0.716797; val_acc: 0.677734\n"
     ]
    }
   ],
   "source": [
    "    # Create model.\n",
    "    model = ConvolutionNet()\n",
    "    # Create data iterators for training and testing sets.\n",
    "\n",
    "    train_dataiter = NDArrayIter(data=data['X_train'],\n",
    "                                 label=data['y_train'],\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True)\n",
    "    test_dataiter = NDArrayIter(data=data['X_test'],\n",
    "                                label=data['y_test'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)   \n",
    "    \n",
    "    # Train your CNN model.\n",
    "    solver = Solver(model,\n",
    "                    train_dataiter,\n",
    "                    test_dataiter,\n",
    "                    num_epochs=num_epo,\n",
    "                    init_rule='gaussian',\n",
    "                    init_config={\n",
    "                        'stdvar': 0.001\n",
    "                    },\n",
    "                    #update_rule='sgd_momentum',\n",
    "\t                #update_rule='rmsprop',\n",
    "                    update_rule ='adam', # You may also try different optimization rules\n",
    "                    optim_config={\n",
    "                        'learning_rate': learning_rate\n",
    "                    },\n",
    "                    verbose=True,\n",
    "                    print_every=20)\n",
    "    # Initialize model parameters.\n",
    "    solver.init()\n",
    "    # Train!\n",
    "    solver.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
